---
title: "Artistic Movement Analysis"
author: "Chanuwas (New) Aswamenakul"
date: '2022-10-16'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(data.table)
library(lubridate)
library(stringr)
library(entropy)
library(rsample)
library(cowplot)
library(ggrepel)
library(patchwork)
library(brms)

home_dir <- path.expand("~")
picasso_path <- file.path(home_dir, "Library/CloudStorage/Box-Box/QuantifyingPicasso")

cbPalette <- c('#999999', '#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7')
```

# Data loading

```{r, warning=FALSE}
art_data <- read.delim("raw_data/artwork1.csv", colClasses = "character") # /t as separator

# parse out date, month, and year variables from existing columns
art_data <- art_data %>% 
  separate(dateEnd, c("yearEnd","monthEnd","dayEnd"), remove = FALSE) %>% 
  separate(dateStart, c("yearStart","monthStart","dayStart"), remove = FALSE) %>% 
  mutate(yearEnd = as.numeric(yearEnd),
         monthEnd = as.numeric(monthEnd),
         dayEnd = as.numeric(dayEnd),
         yearStart = as.numeric(yearStart),
         monthStart = as.numeric(monthStart),
         dayStart = as.numeric(dayStart))

# remove weird data (8 entries)
art_data <- art_data %>%
  filter(category != "25~26-March/1936") %>% # shifted column (fixable)
  filter(category != "") %>% # empty rows
  filter(yearEnd != 0) # 2 entries w/ missing end dates

# number of years to finish
art_data <- art_data %>%
  mutate(yearDuration = yearEnd - yearStart)

# fill months and dates
art_data <- art_data %>% 
  mutate(monthEnd_fix = case_when(monthEnd == 0 ~ 6.5,
                                  TRUE ~ monthEnd),
         dayEnd_fix = case_when(dayEnd == 0 ~ 15.5,
                                  TRUE ~ dayEnd),
         monthStart_fix = case_when(monthStart == 0 ~ 6.5,
                                  TRUE ~ monthStart),
         dayStart_fix = case_when(dayStart == 0 ~ 15.5,
                                  TRUE ~ dayStart)) %>%
  mutate(dateEnd = make_date(yearEnd, monthEnd_fix, dayEnd_fix), # convert dateEnd into date type
         dateStart = make_date(yearStart, monthStart_fix, dayStart_fix), # convert dateStart into date type
         yearMonthStart = yearStart + monthStart_fix/12 + dayStart_fix/365) %>% # convert date into year scale
  mutate(date_duration = dateEnd - dateStart)

# select necessary columns
reduced_art <- art_data %>% 
  select(opp, title, category, dayStart, monthStart, yearStart, yearMonthStart, dateStart)

paintings <- reduced_art %>% 
  filter(category == "painting")

# Set up non-overlapping windows
annualBins <- 12 # 12 months
windowSize <- 1/annualBins # window size on the year scale (1 month)

# major artistic periods
majorPeriodOnset <- tibble(period = c("Blue",
                                      "Rose",
                                      "Les Demoiselles d'Avignon",
                                      "Horta de Hebra landscapes",
                                      "Analytic Cubism",
                                      "Synthetic Cubism",
                                      "WW1 Start",
                                      "Neoclassicism", 
                                      "Surrealism\n(Mandoline et guitare)",
                                      "Surrealism\n(Trois denseurs)"),
                           yearMonthStart = c(1901,
                                              1904, 
                                              1907.583,
                                              1909.750,
                                              1912 + 9/12, # changed from 9/12
                                              1912.5,
                                              1914.5, 
                                              1918, 
                                              1924.583, 
                                              1925+2/12)) %>% 
  mutate(timeWindow = ceiling(yearMonthStart / windowSize) * windowSize,
         onsetYear = floor(timeWindow))
```


# Load PCA results

```{r}
feature_path <- file.path(picasso_path, "data_from_OPP/image_features")
target_cat <- "painting"
feature_model <- "resnet"

full_df <- fread(file.path(feature_path, paste0("pca_", target_cat, "_", feature_model, ".csv"))) %>% 
  as.data.frame()

# Separate low-level and high-level features for analyses
low_cols <- str_detect(colnames(full_df), "low")
low_features <- full_df[low_cols]

high_cols <- str_detect(colnames(full_df), "high")
high_features <- full_df[high_cols]

full_pc_cols <- str_detect(colnames(full_df), "pc")
full_features <- full_df[full_pc_cols]
```

```{r}
# enable local access to Box folders
tmp_filelist <- list.files(feature_path)
```


# Movement characterization

## Characterizing distributions

```{r}
source("mvt_analysis.R")
```


## Burstiness sensitivity

```{r}
## pre-calculate movement vectors
ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)

# aggregate data into different windows
window_size <- 7

first_date <- min(ordered_df$dateStart)
ordered_df <- ordered_df %>% 
  mutate(day_count = as.numeric(dateStart - first_date),
         date_group = floor(day_count/window_size))

agg_pca <- ordered_df %>% 
  group_by(date_group) %>% 
  summarize(across(contains("_pc"), mean))

trimmed_pca1 <- agg_pca[-1,] # remove the first row
trimmed_pca2 <- agg_pca[-nrow(agg_pca),] # remove the last row

mvt_df <- trimmed_pca1 - trimmed_pca2

## Step sizes
step_sizes <- mvt_df %>% 
  mutate(across(contains("_pc"), ~ . ^2)) %>% 
  select(contains("_pc")) %>% 
  rowSums() %>% 
  as.vector() %>% 
  sqrt()

## varying threshold for burstiness calculation
burst_threshs <- seq(-2, 3, by=0.1)

result_list <- list(thresh = c(),
                    burstiness = c(),
                    big_count = c(),
                    iei_sd = c(),
                    iei_mean = c())

for (thresh in burst_threshs) {
  result_list$thresh <- c(result_list$thresh, thresh)
  
  ## Burstiness
  bigsteps <- detect_burst(step_sizes, thresh=thresh)
  iei <- extract_iei(bigsteps)[-1]
  
  result_list$burstiness <- c(result_list$burstiness, burstiness(iei))
  result_list$big_count <- c(result_list$big_count, sum(burst_df$bigstep))
  result_list$iei_sd <- c(result_list$iei_sd, sd(iei))
  result_list$iei_mean <- c(result_list$iei_mean, mean(iei))
}

burstsen_results <- data.frame(result_list)

burstsen_results
burstsen_results %>% 
  ggplot(aes(x=thresh, y=burstiness)) +
  geom_point() +
  xlab("big-step threshold") +
  ylim(c(-1,1)) +
  theme_minimal()


# visualize bursts
# ggplot(tibble(bigstep = as.integer(bigsteps), ind = 1:length(bigsteps)),
#        aes(x = ind, y = bigstep)) +
#   geom_col() +
#   ylim(c(0,10))
```


## Fixed coarse-graining

```{r movement analysis}
ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)


# daily level movements
d_ordered_pca <- ordered_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  select(-dateStart)

trimmed_pca1 <- d_ordered_pca[-1,] # remove the first row
trimmed_pca2 <- d_ordered_pca[-nrow(d_ordered_pca),] # remove the last row

## Cosine step sizes
abs_step_sizes <- d_ordered_pca %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

d_step_sizes <- (1 - dot_pca/size_product)/2

## Directional changes (cosine similarity)
mvt_df <- trimmed_pca1 - trimmed_pca2

trimmed_mvt1 <- mvt_df[-1,] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),] # remove the last row

### Euclidean distance of the step
abs_step_sizes <- mvt_df %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

d_cos_sims <- dot_pca/size_product


# monthly level movements
m_ordered_pca <- ordered_df %>% 
  group_by(year(dateStart), month(dateStart)) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  select(-1, -2)

trimmed_pca1 <- m_ordered_pca[-1,] # remove the first row
trimmed_pca2 <- m_ordered_pca[-nrow(m_ordered_pca),] # remove the last row

mvt_df <- trimmed_pca1 - trimmed_pca2

## Cosine step sizes
abs_step_sizes <- m_ordered_pca %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

m_step_sizes <- (1 - dot_pca/size_product)/2

## Directional changes (cosine similarity)
mvt_df <- trimmed_pca1 - trimmed_pca2

trimmed_mvt1 <- mvt_df[-1,] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),] # remove the last row

### Euclidean distance of the step
abs_step_sizes <- mvt_df %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

m_cos_sims <- dot_pca/size_product


# yearly level movements
y_ordered_pca <- ordered_df %>% 
  group_by(year(dateStart)) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  select(-1)

trimmed_pca1 <- y_ordered_pca[-1,] # remove the first row
trimmed_pca2 <- y_ordered_pca[-nrow(y_ordered_pca),] # remove the last row

mvt_df <- trimmed_pca1 - trimmed_pca2

## Cosine step sizes
abs_step_sizes <- y_ordered_pca %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

y_step_sizes <- (1 - dot_pca/size_product)/2

## Directional changes (cosine similarity)
mvt_df <- trimmed_pca1 - trimmed_pca2

trimmed_mvt1 <- mvt_df[-1,] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),] # remove the last row

### Euclidean distance of the step
abs_step_sizes <- mvt_df %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

y_cos_sims <- dot_pca/size_product


# Visualizing step sizes
dstep_plot <- qplot(d_step_sizes, bins = 100) +
  xlim(c(0, 1)) +
  labs(title = "daily-level step size") +
  theme_minimal() +
  theme(axis.title.x=element_blank()) 
mstep_plot <- qplot(m_step_sizes, bins = 100) +
  xlim(c(0, 1)) +
  labs(title = "monthly-level step size") +
  theme_minimal() +
  theme(axis.title.x=element_blank()) 
ystep_plot <- qplot(y_step_sizes, bins = 100) +
  xlab("euclidean distance") +
  xlim(c(0, 1)) +
  labs(title = "yearly-level step size") +
  theme_minimal() +
  theme(axis.title.x=element_blank()) 

dstep_plot / mstep_plot / ystep_plot

ggsave(paste0("img/cstep_size_dist_", feature_model, ".png"))

# Visualizing cosine similarity
csd_plot <- qplot(d_cos_sims, bins = 100) +
  xlim(c(-1, 1)) +
  xlab("cosine similarity") +
  labs(title = "daily-level directional change") +
  theme_minimal() +
  theme(axis.title.x=element_blank())
csm_plot <- qplot(m_cos_sims, bins = 100) +
  xlim(c(-1, 1)) +
  xlab("cosine similarity") +
  labs(title = "monthly-level directional change") +
  theme_minimal() +
  theme(axis.title.x=element_blank())
csy_plot <- qplot(y_cos_sims, bins = 100) +
  xlim(c(-1, 1)) +
  xlab("cosine similarity") +
  labs(title = "yearly-level directional change") +
  theme_minimal() +
  theme(axis.title.x=element_blank())

csd_plot / csm_plot / csy_plot
# ggsave(paste0("img/direct_change_dist_", feature_model, ".png"))
```

```{r}
stepsize_df <- stepsize_df %>% 
  mutate(career_stage = case_when(dateStart < ymd("1910-01-01") ~ "1early",
                                  dateStart < ymd("1920-01-01") ~ "2mid",
                                  dateStart < ymd("1930-01-01") ~ "3mid",
                                  dateStart < ymd("1940-01-01") ~ "4mid",
                                  TRUE ~ "5late"))

stepsize_df %>%
  ggplot(aes(x=stepsize, fill=career_stage, group = career_stage)) + 
  geom_density(alpha=.5) + 
  facet_wrap(~career_stage) +
  theme_classic()
```

### null model

```{r}
# shuffle date column and arrange dataframe
shuff_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  transform(dateStart = sample(dateStart)) %>% 
  arrange(dateStart) %>% 
  select(dateStart, low_pc1:high_pc100)

shuff_df %>% head()

# daily level movements
d_ordered_pca <- shuff_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  select(-dateStart)

trimmed_pca1 <- d_ordered_pca[-1,] # remove the first row
trimmed_pca2 <- d_ordered_pca[-nrow(d_ordered_pca),] # remove the last row

## Cosine step sizes
abs_step_sizes <- d_ordered_pca %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

nd_step_sizes <- (1 - dot_pca/size_product)/2

## Directional changes (cosine similarity)
mvt_df <- trimmed_pca1 - trimmed_pca2

trimmed_mvt1 <- mvt_df[-1,] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),] # remove the last row

### Euclidean distance of the step
abs_step_sizes <- mvt_df %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

nd_cos_sims <- dot_pca/size_product


# monthly level movements
m_ordered_pca <- shuff_df %>% 
  group_by(year(dateStart), month(dateStart)) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  select(-1, -2)

trimmed_pca1 <- m_ordered_pca[-1,] # remove the first row
trimmed_pca2 <- m_ordered_pca[-nrow(m_ordered_pca),] # remove the last row

mvt_df <- trimmed_pca1 - trimmed_pca2

## Cosine step sizes
abs_step_sizes <- m_ordered_pca %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

nm_step_sizes <- (1 - dot_pca/size_product)/2

## Directional changes (cosine similarity)
mvt_df <- trimmed_pca1 - trimmed_pca2

trimmed_mvt1 <- mvt_df[-1,] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),] # remove the last row

### Euclidean distance of the step
abs_step_sizes <- mvt_df %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

nm_cos_sims <- dot_pca/size_product


# yearly level movements
y_ordered_pca <- shuff_df %>% 
  group_by(year(dateStart)) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  select(-1)

trimmed_pca1 <- y_ordered_pca[-1,] # remove the first row
trimmed_pca2 <- y_ordered_pca[-nrow(y_ordered_pca),] # remove the last row

mvt_df <- trimmed_pca1 - trimmed_pca2

## Cosine step sizes
abs_step_sizes <- y_ordered_pca %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

ny_step_sizes <- (1 - dot_pca/size_product)/2

## Directional changes (cosine similarity)
mvt_df <- trimmed_pca1 - trimmed_pca2

trimmed_mvt1 <- mvt_df[-1,] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),] # remove the last row

### Euclidean distance of the step
abs_step_sizes <- mvt_df %>%
  mutate(across(contains("_pc"), ~ . ^2)) %>%
  select(contains("_pc")) %>%
  rowSums() %>%
  as.vector() %>%
  sqrt()

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]

ny_cos_sims <- dot_pca/size_product


# Visualizing step sizes
ndstep_plot <- qplot(nd_step_sizes, bins = 100) +
  xlim(c(0, 1)) +
  labs(title = "daily-level step size") +
  theme_minimal() +
  theme(axis.title.x=element_blank()) 
nmstep_plot <- qplot(nm_step_sizes, bins = 100) +
  xlim(c(0, 1)) +
  labs(title = "monthly-level step size") +
  theme_minimal() +
  theme(axis.title.x=element_blank()) 
nystep_plot <- qplot(ny_step_sizes, bins = 100) +
  xlab("euclidean distance") +
  xlim(c(0, 1)) +
  labs(title = "yearly-level step size") +
  theme_minimal() +
  theme(axis.title.x=element_blank()) 

ndstep_plot / nmstep_plot / nystep_plot
ggsave(paste0("img/cstep_size_dist_null.png"))


# Visualizing cosine similarity
ncsd_plot <- qplot(nd_cos_sims, bins = 100) +
  xlim(c(-1, 1)) +
  xlab("cosine similarity") +
  labs(title = "daily-level directional change") +
  theme_minimal() +
  theme(axis.title.x=element_blank())
ncsm_plot <- qplot(nm_cos_sims, bins = 100) +
  xlim(c(-1, 1)) +
  xlab("cosine similarity") +
  labs(title = "monthly-level directional change") +
  theme_minimal() +
  theme(axis.title.x=element_blank())
ncsy_plot <- qplot(ny_cos_sims, bins = 100) +
  xlim(c(-1, 1)) +
  xlab("cosine similarity") +
  labs(title = "yearly-level directional change") +
  theme_minimal() +
  theme(axis.title.x=element_blank())

ncsd_plot / ncsm_plot / ncsy_plot

# ggsave(paste0("img/direct_change_dist_null.png"))
```

### Statistics

```{r}
tmp_df <- tibble(t = 1:length(d_cos_sims), dir_change = d_cos_sims)

t.test(d_cos_sims)

# dir_prior <- c(
#   prior(normal(0, 1), class = Intercept),
#   prior(exponential(1), class = sigma)
# )
# 
# brm_dir <- brm(dir_change ~ 1,
#             data = tmp_df,
#             family = gaussian(),
#             prior = dir_prior,
#             iter = 2000,
#             chains = 4,
#             cores = 4,
#             warmup = 1000,
#             save_pars = save_pars(all = TRUE))
# 
# brm_dir
```


### Dot and whisker plots

```{r}
mean_step <- c(mean(d_step_sizes), mean(nd_step_sizes))
step_se <- c(stderror(d_step_sizes), stderror(nd_step_sizes))

mean_cossim <- c(mean(d_cos_sims), mean(nd_cos_sims))
cossim_se <- c(stderror(d_cos_sims), stderror(nd_cos_sims))

source <- c("real", "null")

summary_df <- data.frame(step_size = mean_step,
                         step_se = step_se,
                         cos_sim = mean_cossim,
                         cossim_se = cossim_se,
                         source = source)


dw_plot <- summary_df %>% 
  ggplot(aes(x = step_size, y = cos_sim, color = source)) +
  geom_point(size=2) +
  geom_errorbar(aes(ymin = cos_sim - cossim_se,
                    ymax = cos_sim + cossim_se),
                width = 0.005) +
  geom_errorbarh(aes(xmin = step_size - step_se,
                     xmax = step_size + step_se),
                 height = 0.0025) +
  scale_x_continuous(name = expression("Stylistic Change, "*Delta*"("*s[t]*","*s[t+1]*")")) +
  scale_y_continuous(name = expression("Direction Change, "*tau*"("*v[t]*","*v[t+1]*")")) +
  theme_classic(base_size = 14)

ggsave(paste0("img/movement_dot_whisker.png"))
```

### Heatmap with Gaussian Kernel Density

```{r}
library(ks)

df <- tibble(step_size = d_step_sizes[2:length(d_step_sizes)], cos_sim = d_cos_sims)

df.probs1 <- ks::kde(df,
                     xmin=c(0, -1),
                     xmax=c(+1, +1))

kde_matrix1 <- df.probs1$estimate

rownames(kde_matrix1) <- df.probs1$eval.points[[1]]
colnames(kde_matrix1) <- df.probs1$eval.points[[2]]

kde_tb1 <- reshape2::melt(kde_matrix1) %>%
  rename(step_size = Var1, cos_sim = Var2)

heatmap_plot <- kde_tb1 %>% ggplot(aes(x=step_size, y=cos_sim)) + 
  geom_tile(aes(fill=value)) +
  geom_contour(aes(z=value),
               color="black",
               breaks = c(0.4, 1, 1.8, 2.4)) +
  scale_x_continuous("step size", expand=c(0,0)) +
  scale_y_continuous("turn angle", expand=c(0,0)) +
  scale_fill_continuous(name = "Density") +
  theme_classic() +
  theme(text = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.position = "none",
        panel.background = element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"),
        panel.border = element_rect(colour = "black",
                                    fill=NA, linewidth=3))

cstep_density <- data.frame(d_step_sizes) %>% 
  ggplot(aes(x = d_step_sizes)) +
  geom_histogram(aes(y=..density..), bins=50) +
  geom_density() +
  scale_x_continuous(limits=c(0,1)) +
  theme_classic()

turn_density <- data.frame(d_cos_sims) %>% 
  ggplot(aes(y = d_cos_sims)) +
  geom_histogram(aes(x=..density..), bins=50) +
  geom_density() +
  scale_y_continuous(limits=c(-1,1)) +
  theme_classic()

cstep_density
turn_density
heatmap_plot

plot_grid(
  cstep_density, NULL, heatmap_plot, turn_density,
  rel_widths = c(4, 1),
  rel_heights = c(1, 4),
  ncol = 2
)
# ggsave(file.path("img", "step_heatmap.png"), height = 7, width = 9)

ggsave(file.path("img", "movement_density.jpg"), height = 9, width = 10)
```

```{r}
# heatmap for null data
ndf <- tibble(step_size = nd_step_sizes[2:length(d_step_sizes)], cos_sim = nd_cos_sims)

ndf.probs1 <- ks::kde(ndf,
                      xmin=c(0, -1),
                      xmax=c(+1, +1))

kde_matrix2 <- ndf.probs1$estimate

rownames(kde_matrix2) <- ndf.probs1$eval.points[[1]]
colnames(kde_matrix2) <- ndf.probs1$eval.points[[2]]

kde_tb2 <- reshape2::melt(kde_matrix2) %>%
  rename(step_size = Var1, cos_sim = Var2)

kde_tb2 %>% ggplot(aes(x=step_size, y=cos_sim)) + 
  geom_tile(aes(color=value, fill=value)) +
  geom_contour(aes(z=value),
               color="black",
               breaks = c(0.4, 1, 1.8, 2.4)) +
  scale_x_continuous(expand=c(0,0)) +
  scale_y_continuous(expand=c(0,0)) +
  theme_classic()

ggsave(file.path("img", "stepnull_heatmap.png"), height = 6, width = 12)
```



## Parametric coarse-graining

```{r}
source("mvt_analysis.R")

ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)

wsize_list <- 1:730 # c(1, 7, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 365, 730)

step_thresh <- 1
cos_thresh <- 0

agg_results <- parametric_coarse_grain(ordered_df, wsize_list = wsize_list,
                                       step_thresh = step_thresh,
                                       cos_thresh = cos_thresh)

write_csv(agg_results,
          file.path(picasso_path, "results",
                    "mvt_coarsed_results.csv"))
```

### null model

```{r}
source("mvt_analysis.R")

ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  mutate(dateStart = sample(dateStart)) %>% 
  arrange(dateStart) %>% 
  select(dateStart, low_pc1:high_pc100)

wsize_list <- c(1, 7, 30, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330, 365, 730)

step_thresh <- 1
cos_thresh <- 0

agg_results <- parametric_coarse_grain(ordered_df, wsize_list = wsize_list,
                                       step_thresh = step_thresh,
                                       cos_thresh = cos_thresh)

write_csv(agg_results,
          file.path(picasso_path, "results",
                    "null_mvt_coarsed_results.csv"))
```

### Result visualization

```{r}
agg_results <- read_csv(file.path(picasso_path, "results", "mvt_coarsed_results.csv"))
# filter(window_size <= 365)

nagg_results <- read_csv(file.path(picasso_path, "results", "null_mvt_coarsed_results.csv"))

agg_results %>% glimpse()
```


```{r}
agg_results %>% 
  ggplot(aes(x=window_size)) + 
  geom_line(aes(y=step_avg)) + 
  geom_pointrange(aes(y=step_avg,
                      ymin=step_avg - step_se, 
                      ymax=step_avg + step_se)) +
  scale_y_continuous(limits=c(0, 1)) + 
  theme_classic()
ggsave("img/step_coarsed.png")


agg_results %>% 
  ggplot(aes(x=window_size)) + 
  geom_line(aes(y=dir_avg)) + 
  geom_pointrange(aes(y=dir_avg,
                      ymin=dir_avg - dir_se, 
                      ymax=dir_avg + dir_se)) +
  scale_y_continuous(limits=c(-1, 1)) + 
  theme_classic()
ggsave("img/dir_coarsed.png")



agg_results %>% 
  ggplot(aes(x=dir_avg, y=step_avg, color=window_size)) + 
  # geom_line() + 
  geom_point() +
  geom_errorbar(aes(ymin = step_avg - step_se,
                    ymax = step_avg + step_se),
                width = 0.0025) +
  # geom_errorbarh(aes(xmin = dir_avg - dir_se,
  #                    xmax = dir_avg + dir_se),
  #                height = 0.0025) +
  geom_hline(yintercept=0, linetype='dashed') +
  geom_vline(xintercept=0, linetype='dashed') +
  scale_y_continuous(limits=c(0,0.5)) + 
  theme_classic()

# ggsave("img/coarsed_mvt3.png")

# agg_results %>%
#   ggplot(aes(x=step_avg, y=step_burst, color=window_size)) +
#   geom_line() +
#   geom_point() +
#   geom_hline(yintercept=0, linetype='dashed') +
#   geom_vline(xintercept=0, linetype='dashed') +
#   scale_y_continuous(limits=c(-1,1)) +
#   theme_classic()

agg_results %>% 
  ggplot(aes(x=window_size)) + 
  geom_line(aes(y=step_burst)) + 
  geom_point(aes(y=step_burst)) +
  geom_hline(yintercept=0, linetype='dashed') +
  scale_y_continuous(limits=c(-1, 1)) + 
  theme_classic()

ggsave("img/stepburst_coarsed.png", width = 12, height = 7)

nagg_results %>% 
  ggplot(aes(x=window_size)) + 
  geom_line(aes(y=step_burst)) + 
  geom_point(aes(y=step_burst)) +
  geom_hline(yintercept=0, linetype='dashed') +
  scale_y_continuous(limits=c(-1, 1)) + 
  theme_classic()

ggsave("img/nstepburst_coarsed.png", width = 12, height = 7)
```


## Step sizes at different intervals

```{r}
ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(yearStart >= 1900, monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)

first_date <- min(ordered_df$dateStart)
last_date <- max(ordered_df$dateStart)

# daily level movements
d_ordered_pca <- ordered_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  complete(dateStart = seq(first_date, last_date, by = "1 day"))


# interval_list <- c(1, 7, 14, 30, 60, 90, 120, 180, 365)
interval_list <- seq(from = 1, to = 365*5, by = 1)
result_list <- list(step_avg = c(),
                    step_sd = c())

for (interval in interval_list) {
  df_nrow <- nrow(d_ordered_pca)
  
  trimmed_pca1 <- d_ordered_pca[-(1:interval),] # remove the first (interval) rows
  trimmed_pca2 <- d_ordered_pca[-((df_nrow-interval+1):df_nrow),] # remove the last (interval) rows
  
  mvt_df <- trimmed_pca1 - trimmed_pca2
  
  ## Step sizes
  d_step_sizes <- mvt_df %>% 
    mutate(across(contains("_pc"), ~ . ^2)) %>% 
    select(contains("_pc")) %>% 
    rowSums() %>% 
    as.vector() %>% 
    sqrt()
  
  result_list$step_avg <- c(result_list$step_avg, mean(d_step_sizes, na.rm = T))
  result_list$step_sd <- c(result_list$step_sd, sd(d_step_sizes, na.rm = T))
}

result_list$interval <- 1:length(result_list$step_avg)
result_df <- data.frame(result_list)

write_csv(result_df,
          file.path(picasso_path, "results",
                    "filtered_steps_diff_intervals.csv"))
```


```{r}
result_df <- read_csv(file.path(picasso_path, "results", "filtered_steps_diff_intervals.csv"))

ggplot(result_df, aes(x = interval, y = step_avg)) +
  geom_point()

ggsave(file.path("img", "filtered_interval_stepsize.png"))
```

### null model

```{r}
# Null results by permutating data based on dates

d_ordered_pca <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(yearStart >= 1900, monthStart != 0, dayStart != 0) %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop")

first_date <- min(ordered_df$dateStart)
last_date <- max(ordered_df$dateStart)

# shuffle date column and arrange dataframe
d_ordered_pca <- d_ordered_pca %>% 
  mutate(dateStart = sample(dateStart)) %>% 
  arrange(dateStart) %>% 
  select(dateStart, low_pc1:high_pc100) %>% 
  complete(dateStart = seq(first_date, last_date, by = "1 day"))

# interval_list <- c(1, 7, 14, 30, 60, 90, 120, 180, 365)
interval_list <- seq(from = 1, to = 365*5, by = 1)
result_list <- list(step_avg = c(),
                    step_sd = c())

for (interval in interval_list) {
  df_nrow <- nrow(d_ordered_pca)
  
  trimmed_pca1 <- d_ordered_pca[-(1:interval),] # remove the first (interval) rows
  trimmed_pca2 <- d_ordered_pca[-((df_nrow-interval+1):df_nrow),] # remove the last (interval) rows
  
  mvt_df <- trimmed_pca1 - trimmed_pca2
  
  ## Step sizes
  d_step_sizes <- mvt_df %>% 
    mutate(across(contains("_pc"), ~ . ^2)) %>% 
    select(contains("_pc")) %>% 
    rowSums() %>% 
    as.vector() %>% 
    sqrt()
  
  result_list$step_avg <- c(result_list$step_avg, mean(d_step_sizes, na.rm = T))
  result_list$step_sd <- c(result_list$step_sd, sd(d_step_sizes, na.rm = T))
}

result_list$interval <- interval_list
null_result_df <- data.frame(result_list)

write_csv(null_result_df,
          file.path(picasso_path, "results",
                    "filtered_null_steps_diff_intervals.csv"))
```

```{r}
null_result_df <- read_csv(file.path(picasso_path, "results",
                                     "filtered_null_steps_diff_intervals.csv"))

ggplot(null_result_df, aes(x = interval, y = step_avg)) +
  geom_point()
  # geom_pointrange(aes(ymin = step_avg - step_sd, ymax = step_avg + step_sd)) +
  # ylim(c(-15,60))

ggsave(file.path("img", "filtered_null_interval_stepsize.png"))
```

- could do cumulative sum of cosine similarity for different intervals to smooth out the curve
- Transform x and y axes to log scale and fit a linear regression: the coefficient is the exponent of power-law
- cosine distance between pairs of artwork within 1-month period becomes more negative before major periods and returns to baseline after (cos_sim ~ 1 + time + pre + post)
- K-mean clusters artwork and see patterns of clusters over time (Are there clusters that once showed up is being re-visited repeatedly)
  - delta t_i = time between i^th appearance of cluster and i-1 appearance
  - (delta t_1 - average(delta t_i)) / sd(delta t_i)


```{r}
result_df <- read_csv(file.path(picasso_path, "results",
                                "filtered_steps_diff_intervals.csv"))

null_result_df <- read_csv(file.path(picasso_path, "results",
                                     "filtered_null_steps_diff_intervals.csv"))

ggplot(result_df, aes(x = interval, y = step_avg)) +
  geom_point() +
  geom_point(data = null_result_df, color = "red")

ggsave(file.path("img", "picasso_vs_null_interval_stepsize.png"))
```

### subset by decades

```{r}
ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(yearStart >= 1900, monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)

first_date <- min(ordered_df$dateStart)
last_date <- max(ordered_df$dateStart)

# daily level movements
d_ordered_pca <- ordered_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  complete(dateStart = seq(first_date, last_date, by = "1 day")) %>% 
  mutate(decade = year(dateStart) - (year(dateStart) %% 10))

decade_list <- unique(d_ordered_pca$decade)
result_list <- list()

for (i in length(decade_list)) {
  
  interval_list <- seq(from = 1, to = 365, by = 1)
  decade_result <- list(step_avg = c(),
                        step_sd = c())
  
  decade_pca <- d_ordered_pca %>% 
    filter(decade == decade_list[i])
  
  for (interval in interval_list) {
    df_nrow <- nrow(decade_pca)
    
    trimmed_pca1 <- decade_pca[-(1:interval),] # remove the first (interval) rows
    trimmed_pca2 <- decade_pca[-((df_nrow-interval+1):df_nrow),] # remove the last (interval) rows
    
    mvt_df <- trimmed_pca1 - trimmed_pca2
    
    ## Step sizes
    d_step_sizes <- mvt_df %>% 
      mutate(across(contains("_pc"), ~ . ^2)) %>% 
      select(contains("_pc")) %>% 
      rowSums() %>% 
      as.vector() %>% 
      sqrt()
    
    decade_result$step_avg <- c(decade_result$step_avg, mean(d_step_sizes, na.rm = T))
    decade_result$step_sd <- c(decade_result$step_sd, sd(d_step_sizes, na.rm = T))
  }
  
  decade_result$interval <- 1:length(decade_result$step_avg)
  decade_df <- data.frame(decade_result) %>% 
    mutate(decade = decade_list[i])
  
  result_list[[i]] <- decade_df
}

# bind_rows()

# overlay the overall results with results by decade and color them
# model location change as perturbation to picasso artistic trajectory (related to Alex Peterson)
## quantify effects in step sizes
```


## Cosine distance at different intervals

```{r}
ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(yearStart >= 1900, monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)


first_date <- min(ordered_df$dateStart)
last_date <- max(ordered_df$dateStart)

# daily level movements
d_ordered_pca <- ordered_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop") %>% 
  complete(dateStart = seq(first_date, last_date, by = "1 day"))


# interval_list <- c(1, 7, 14, 30, 60, 90, 120, 180, 365)
interval_list <- seq(from = 1, to = 365*10, by = 1)
result_list <- list(cos_avg = c(),
                    cos_sd = c())

for (interval in interval_list) {
  df_nrow <- nrow(d_ordered_pca)
  
  trimmed_pca1 <- d_ordered_pca[-(1:interval),] %>% # remove the first (interval) rows
    select(contains("_pc"))
  trimmed_pca2 <- d_ordered_pca[-((df_nrow-interval+1):df_nrow),] %>% # remove the last (interval) rows
    select(contains("_pc"))
  
  # Cosine similarity
  dot_products <- (trimmed_pca1 * trimmed_pca2) %>% 
    rowSums()
  
  cur_sizes <- (trimmed_pca1^2) %>%
    rowSums() %>%
    sqrt()
  lag_sizes <- (trimmed_pca2^2) %>%
    rowSums() %>% 
    sqrt()
  
  cos_sims <- dot_products / (cur_sizes * lag_sizes)

  
  result_list$cos_avg <- c(result_list$cos_avg, mean(cos_sims, na.rm = T))
  result_list$cos_sd <- c(result_list$cos_sd, sd(cos_sims, na.rm = T))
}

result_list$interval <- interval_list
result_df <- data.frame(result_list)

write_csv(result_df,
          file.path(picasso_path, "results",
                    "filtered_cossim_intervals.csv"))
```


```{r}
result_df <- read_csv(file.path(picasso_path, "results", "filtered_cossim_intervals.csv"))

ggplot(result_df, aes(x = interval, y = cos_avg)) +
  geom_point()

ggsave(file.path("img", "filtered_interval_cossims.png"))
```

### null model

```{r}
# Null results by permutating data based on dates

d_ordered_pca <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(yearStart >= 1900, monthStart != 0, dayStart != 0) %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean), .groups = "drop")

first_date <- min(d_ordered_pca$dateStart)
last_date <- max(d_ordered_pca$dateStart)

# shuffle date column and arrange dataframe
d_ordered_pca <- d_ordered_pca %>% 
  mutate(dateStart = sample(dateStart)) %>% 
  arrange(dateStart) %>% 
  select(dateStart, low_pc1:high_pc100) %>% 
  complete(dateStart = seq(first_date, last_date, by = "1 day"))

# interval_list <- c(1, 7, 14, 30, 60, 90, 120, 180, 365)
interval_list <- seq(from = 1, to = 365*5, by = 1)
result_list <- list(cos_avg = c(),
                    cos_sd = c())

for (interval in interval_list) {
  df_nrow <- nrow(d_ordered_pca)
  
  trimmed_pca1 <- d_ordered_pca[-(1:interval),] %>% # remove the first (interval) rows
    select(contains("_pc"))
  trimmed_pca2 <- d_ordered_pca[-((df_nrow-interval+1):df_nrow),] %>% # remove the last (interval) rows
    select(contains("_pc"))
  
  # Cosine similarity
  dot_products <- (trimmed_pca1 * trimmed_pca2) %>% 
    rowSums()
  
  cur_sizes <- (trimmed_pca1^2) %>%
    rowSums() %>%
    sqrt()
  lag_sizes <- (trimmed_pca2^2) %>%
    rowSums() %>% 
    sqrt()
  
  cos_sims <- dot_products / (cur_sizes * lag_sizes)

  
  result_list$cos_avg <- c(result_list$cos_avg, mean(cos_sims, na.rm = T))
  result_list$cos_sd <- c(result_list$cos_sd, sd(cos_sims, na.rm = T))
}

result_list$interval <- interval_list
null_result_df <- data.frame(result_list)

write_csv(null_result_df,
          file.path(picasso_path, "results",
                    "filtered_null_cossim_intervals.csv"))
```

```{r}
null_result_df <- read_csv(file.path(picasso_path, "results",
                                     "filtered_null_steps_diff_intervals.csv"))

ggplot(null_result_df, aes(x = interval, y = cos_avg)) +
  geom_point()
  # geom_pointrange(aes(ymin = step_avg - step_sd, ymax = step_avg + step_sd)) +
  # ylim(c(-15,60))

ggsave(file.path("img", "filtered_null_interval_cossim.png"))
```

```{r}
result_df <- read_csv(file.path(picasso_path, "results",
                                "filtered_cossim_intervals.csv"))

null_result_df <- read_csv(file.path(picasso_path, "results",
                                     "filtered_null_cossim_intervals.csv"))

result_df$source <- "real data"
null_result_df$source <- "null data"

combined_results <- bind_rows(result_df, null_result_df) %>% 
  mutate(cstep = (1 - cos_avg) / 2)

ggplot(combined_results, aes(x = interval, y = cstep, color = source)) +
  geom_point() +
  scale_color_manual(values = cbPalette) +
  theme_classic()

ggsave(file.path("img", "picasso_vs_null_interval_cstep.png"),
       width = 12, height = 6)
```


### Bayesian statistics

```{r}
tmp_df <- tibble(t = 1:length(d_cos_sims), dir_change = d_cos_sims)

dir_prior <- c(
  prior(normal(0, 1), class = Intercept),
  prior(exponential(1), class = sigma)
)

brm_dir <- brm(dir_change ~ 1,
            data = tmp_df,
            family = gaussian(),
            prior = dir_prior,
            iter = 2000,
            chains = 4,
            cores = 4,
            warmup = 1000,
            save_pars = save_pars(all = TRUE))

brm_dir
```



## Sliding window analyses

```{r}
ordered_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  arrange(yearStart, monthStart, dayStart) %>% 
  select(dateStart, low_pc1:high_pc100)

agg_pca <- ordered_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean))

step_thresh <- 0.3830784 + (0.1682463 * 2)
cos_thresh <- 0

year_window <- 5 # c(1:70)

first_date <- ymd(18940101)
last_date <- ymd(19720701)

# (last_date - first_date) / 365

window_size <- years(year_window)
wstep_size <- months(1)

wfirst_date <- first_date
wlast_date <- first_date + window_size

result_list <- list(cstep_avg = c(),
                    cstep_sd = c(),
                    loc_burst = c(),
                    date_burst = c())

start_date_seq <- seq(first_date, last_date - window_size + days(1), by = "1 month")
end_date_seq <- seq(wlast_date, last_date, by = "1 month")

while (wlast_date <= last_date) {
  print(paste("start date =", wfirst_date))
  
  # filtering data using the window size
  wagg_pca <- agg_pca %>% 
    filter(dateStart >= wfirst_date, dateStart < wlast_date)
  
  # check if there's only one data point
  if (nrow(wagg_pca) <= 1) {
    result_list$cstep_avg <- c(result_list$cstep_avg, NA)
    result_list$cstep_sd <- c(result_list$cstep_sd, NA)
    result_list$loc_burst <- c(result_list$loc_burst, NA)
    result_list$date_burst <- c(result_list$date_burst, NA)
    
    wfirst_date <- wfirst_date + wstep_size
    wlast_date <- wlast_date + wstep_size
    next
  }
  
  trimmed_pca1 <- wagg_pca[-1,] # remove the first row
  trimmed_pca2 <- wagg_pca[-nrow(wagg_pca),] # remove the last row
  
  # movement vectors
  mvt_df <- trimmed_pca1 - trimmed_pca2
  
  ## Cosine step sizes
  abs_step_sizes <- wagg_pca %>%
    mutate(across(contains("_pc"), ~ . ^2)) %>%
    select(contains("_pc")) %>%
    rowSums() %>%
    as.vector() %>%
    sqrt()
  
  trimmed_pca1 <- trimmed_pca1 %>% select(-dateStart)
  trimmed_pca2 <- trimmed_pca2 %>% select(-dateStart)
  
  dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
  size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]
  
  cstep_sizes <- (1 - dot_pca/size_product)/2
  
  result_list$cstep_avg <- c(result_list$cstep_avg, mean(cstep_sizes))
  result_list$cstep_sd <- c(result_list$cstep_sd, sd(cstep_sizes))
  
  # only calculate if there are at least 2 movement vectors
  if (nrow(mvt_df) > 1) {
    # 0 bigsteps will be NA
    ## Burstiness
    loc_threshold <- mean(cstep_sizes) + (1*sd(cstep_sizes))
    
    loc_bigstep <- detect_burst(cstep_sizes, thresh=loc_threshold, scale=F)
    step_iei1 <- extract_iei(loc_bigstep)[-1]
    
    result_list$loc_burst <- c(result_list$loc_burst, burstiness(step_iei1))
    
    # date burstiness (days that Picasso started artworks)
    avail_dates <- wagg_pca$dateStart
    tmp_date_seq <- seq(wfirst_date, wlast_date - days(1), by = "1 day")
    
    burst_inds <- match(avail_dates, tmp_date_seq)
    date_burst <- rep(0, length(tmp_date_seq))
    date_burst[burst_inds] <- 1
    
    date_burst <- as.logical(date_burst)
    date_iei <- extract_iei(date_burst)[-1]
    
    result_list$date_burst <- c(result_list$date_burst, burstiness(date_iei))
    
  } else {
    result_list$loc_burst <- c(result_list$loc_burst, NA)
    result_list$date_burst <- c(result_list$date_burst, NA)
  }
  
  wfirst_date <- wfirst_date + wstep_size
  wlast_date <- wlast_date + wstep_size
}

slidw_df <- data.frame(result_list)
slidw_df$start_date <- start_date_seq
slidw_df$end_date <- end_date_seq

slidw_df <- slidw_df[,c(5,6,1:4)]
slidw_df

write_csv(slidw_df,
          file.path(picasso_path, "results",
                    paste0("slide_window", year_window, "y_burst1m_2.csv")))
```

```{r}
# ordered_df <- full_df %>% 
#   left_join(art_data %>% select(opp, dayStart, dateStart),
#             by = "opp") %>% 
#   filter(monthStart != 0, dayStart != 0) %>% 
#   arrange(yearStart, monthStart, dayStart) %>% 
#   select(dateStart, low_pc1:high_pc100)
# 
# agg_pca <- ordered_df %>% 
#   group_by(dateStart) %>% 
#   summarize(across(contains("_pc"), mean))
# 
# step_thresh <- 0.3830784 + (0.1682463 * 2)
# cos_thresh <- 0
# 
# year_window <- 1 # c(1:57, 70)
# 
# first_date <- ymd(18940101)
# last_date <- ymd(19720701)
# 
# window_size <- years(year_window)
# wstep_size <- days(1)
# 
# wfirst_date <- first_date
# wlast_date <- first_date + window_size
# 
# result_list <- list(step_avg = c(),
#                     step_sd = c(),
#                     cstep_avg = c(),
#                     cstep_sd = c(),
#                     dir_avg = c(),
#                     dir_sd = c())
# 
# start_date_seq <- seq(first_date, last_date - window_size + days(1), by = "1 day")
# end_date_seq <- seq(wlast_date, last_date, by = "1 day")
# 
# # figure out what to do if there's only 1 data point in the window
# while (wlast_date <= last_date) {
#   print(paste("start date =", wfirst_date))
# 
#   # filtering data using the window size
#   wagg_pca <- agg_pca %>%
#     filter(dateStart >= wfirst_date, dateStart <= wlast_date)
# 
#   # check if there's only one data point
#   if (nrow(wagg_pca) <= 1) {
#     result_list$step_avg <- c(result_list$step_avg, NA)
#     result_list$step_sd <- c(result_list$step_sd, NA)
#     result_list$cstep_avg <- c(result_list$cstep_avg, NA)
#     result_list$cstep_sd <- c(result_list$cstep_sd, NA)
#     result_list$dir_avg <- c(result_list$dir_avg, NA)
#     result_list$dir_sd <- c(result_list$dir_sd, NA)
# 
#     wfirst_date <- wfirst_date + wstep_size
#     wlast_date <- wlast_date + wstep_size
#     next
#   }
# 
#   trimmed_pca1 <- wagg_pca[-1,] # remove the first row
#   trimmed_pca2 <- wagg_pca[-nrow(wagg_pca),] # remove the last row
# 
#   # movement vectors
#   mvt_df <- trimmed_pca1 - trimmed_pca2
# 
#   ## Step sizes (Euclidean distance)
#   step_sizes <- mvt_df %>%
#     mutate(across(contains("_pc"), ~ . ^2)) %>%
#     select(contains("_pc")) %>%
#     rowSums() %>%
#     as.vector() %>%
#     sqrt()
# 
#   result_list$step_avg <- c(result_list$step_avg, mean(step_sizes))
#   result_list$step_sd <- c(result_list$step_sd, sd(step_sizes))
# 
#   ## Cosine step sizes
#   abs_step_sizes <- wagg_pca %>%
#     mutate(across(contains("_pc"), ~ . ^2)) %>%
#     select(contains("_pc")) %>%
#     rowSums() %>%
#     as.vector() %>%
#     sqrt()
# 
#   trimmed_pca1 <- trimmed_pca1 %>% select(-dateStart)
#   trimmed_pca2 <- trimmed_pca2 %>% select(-dateStart)
# 
#   dot_pca <- rowSums(trimmed_pca1*trimmed_pca2)
#   size_product <- abs_step_sizes[-1]*abs_step_sizes[-length(abs_step_sizes)]
# 
#   cstep_sizes <- (1 - dot_pca/size_product)/2
# 
#   result_list$cstep_avg <- c(result_list$cstep_avg, mean(cstep_sizes))
#   result_list$cstep_sd <- c(result_list$cstep_sd, sd(cstep_sizes))
# 
#   # only calculate if there are at least 2 movement vectors
#   if (nrow(mvt_df) > 1) {
#     ## Directional changes (cosine similarity)
#     trimmed_mvt1 <- mvt_df[-1,-1] # remove the first row
#     trimmed_mvt2 <- mvt_df[-nrow(mvt_df),-1] # remove the last row
# 
#     dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
#     size_product <- step_sizes[-1]*step_sizes[-length(step_sizes)]
# 
#     cos_sims <- dot_pca/size_product
# 
#     result_list$dir_avg <- c(result_list$dir_avg, mean(cos_sims))
#     result_list$dir_sd <- c(result_list$dir_sd, sd(cos_sims))
#     
#   } else {
#     result_list$dir_avg <- c(result_list$dir_avg, NA)
#     result_list$dir_sd <- c(result_list$dir_sd, NA)
#   }
# 
#   wfirst_date <- wfirst_date + wstep_size
#   wlast_date <- wlast_date + wstep_size
# }
# 
# slidw_df <- data.frame(result_list)
# slidw_df$start_date <- start_date_seq
# slidw_df$end_date <- end_date_seq
# 
# slidw_df <- slidw_df[,c(7,8,1:6)]
# slidw_df
# 
# write_csv(slidw_df,
#           file.path(picasso_path, "results",
#                     "slide_window12m_step.csv"))
```


```{r}
avg_loc_bursts <- c()

for (i in c(1:70)) {
  slidw_df <- read_csv(file.path(picasso_path, "results",
                                 paste0("slide_window", i, "y_burst1m_2.csv")))
  
 
  avg_loc_bursts <- c(avg_loc_bursts, mean(slidw_df$loc_burst, na.rm = T))
}

loc_burst_df <- data.frame(year_wsize = c(1:70), loc_burst = avg_loc_bursts)

loc_burst_df %>% 
  ggplot(aes(x = year_wsize, y = loc_burst)) +
  geom_point() +
  geom_line() +
  theme_classic()

ggsave("img/locsd1_burst_vary_wsize.png", width = 12, height = 6)
```


```{r}
slidw_df <- read_csv(file.path(picasso_path, "results", "slide_window12m_step.csv"))

majorPeriodOnset <- majorPeriodOnset %>% 
  mutate(month = ceiling(12 * ((yearMonthStart+.001) - 
                               floor(yearMonthStart))),
         year = floor(yearMonthStart),
         day = "1", 
         yearMonthDay = paste(year, month, day, sep="-")) %>%
  rowwise() %>%
  mutate(start_date = ymd(yearMonthDay))

# loc_burst = step_burst1, globe_burst = step_burst2
# majorPeriodOnset <- majorPeriodOnset %>%
#   left_join(slidw_df %>% select(start_date, step_avg, cstep_avg, dir_avg, loc_burst, globe_burst, dir_burst))

majorPeriodOnset <- majorPeriodOnset %>%
  left_join(slidw_df %>% select(start_date, cstep_avg))
```

```{r}
# sliding window visualizations
slidw_df %>% 
  ggplot(aes(x = start_date, y = cstep_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=cstep_avg+.25), alpha=.5) +
  scale_x_continuous("date (started)") +
  scale_y_continuous("step size") +
  theme_minimal() +
  theme(text = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        axis.title.y = element_text(size = 20),
        legend.position = "none")

ggsave(file.path("img", "slidw1y_step1d_cstep.png"),
       width = 8, height = 6)
  

slidw_df %>% 
  ggplot(aes(x = start_date, y = step_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=step_avg+5), alpha=.5) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")

slidw_df %>% 
  ggplot(aes(x = start_date, y = dir_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=dir_avg+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  # coord_cartesian(xlim = c(1898,1928)) +
  theme_minimal() +
  theme(legend.position = "none")

slidw_df %>% 
  ggplot(aes(x = start_date, y = dir_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=dir_avg+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")

slidw_df %>% 
  ggplot(aes(x = start_date, y = loc_burst)) +
  geom_point() +
  # geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  theme_classic() +
  theme(legend.position = "none")

ggsave(file.path("img", "slidw2y_step1m_loc1.5sd_burstiness.png"),
       width = 12, height = 6)

slidw_df %>% 
  ggplot(aes(x = start_date, y = loc_burst)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=loc_burst+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")

slidw_df %>% 
  ggplot(aes(x = start_date, y = dir_burst)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=dir_burst+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
slidw_df <- slidw_df %>% 
  mutate(rescaled_loc_burst = (loc_burst + 1) / 2,
         rescaled_date_burst = (date_burst + 1) / 2,
         adjust_burst = log(rescaled_loc_burst / rescaled_date_burst))

slidw_df$adjust_burst[is.infinite(slidw_df$adjust_burst)] <- NA

slidw_df %>% 
  summarize(avg_loc_burst = mean(rescaled_loc_burst, na.rm = T),
            avg_date_burst = mean(rescaled_date_burst, na.rm = T),
            mean_adj_burst = mean(adjust_burst, na.rm = T)) %>% 
  mutate(adjust_avg_burst = avg_loc_burst / avg_date_burst)

slidw_df %>% 
  ggplot(aes(x=start_date, y=adjust_burst)) +
  geom_point() +
  theme_classic()

ggsave("img/slidw1y_adjusted_burstiness.png")
```

### Null sliding window

```{r, warning=FALSE}
# shuffle date column and arrange dataframe
shuff_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  transform(dateStart = sample(dateStart)) %>% 
  arrange(dateStart) %>% 
  select(dateStart, low_pc1:high_pc100)

shuff_df %>% head()

agg_pca <- shuff_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean))

cos_thresh <- 0

first_date <- ymd(18940101)
last_date <- ymd(19720701)
window_size <- days(30*6)
wstep_size <- days(1)

wfirst_date <- first_date
wlast_date <- first_date + window_size - days(1)

result_list <- list(step_avg = c(),
                    step_sd = c(),
                    dir_avg = c(),
                    dir_sd = c(),
                    step_burst1 = c(),
                    step_burst2 = c(),
                    dir_burst = c())

start_date_seq <- seq(first_date, last_date - window_size + days(1), by = "1 day")
end_date_seq <- seq(wlast_date, last_date, by = "1 day")

start_year <- year(wfirst_date)
print(paste("year =", start_year))

# figure out what to do if there's only 1 data point in the window
while (wlast_date <= last_date) {
  if (year(wfirst_date) > start_year) {
    start_year <- year(wfirst_date)
    print(paste("year =", start_year))
  }
  
  # filtering data using the window size
  wagg_pca <- agg_pca %>% 
    filter(dateStart >= wfirst_date, dateStart <= wlast_date)
  
  # check if there's only one data point
  if (nrow(wagg_pca) == 1) {
    result_list$step_avg <- c(result_list$step_avg, 0)
    result_list$step_sd <- c(result_list$step_sd, 0)
    result_list$dir_avg <- c(result_list$dir_avg, 0)
    result_list$dir_sd <- c(result_list$dir_sd, 0)
    result_list$step_burst1 <- c(result_list$step_burst1, NA)
    result_list$step_burst2 <- c(result_list$step_burst2, NA)
    result_list$dir_burst <- c(result_list$dir_burst, NA)
    
    wfirst_date <- wfirst_date + wstep_size
    wlast_date <- wlast_date + wstep_size
    next
  }
  
  trimmed_pca1 <- wagg_pca[-1,] # remove the first row
  trimmed_pca2 <- wagg_pca[-nrow(wagg_pca),] # remove the last row
  
  # movement vectors
  mvt_df <- trimmed_pca1 - trimmed_pca2
  
  ## Step sizes
  step_sizes <- mvt_df %>% 
    mutate(across(contains("_pc"), ~ . ^2)) %>% 
    select(contains("_pc")) %>% 
    rowSums() %>% 
    as.vector() %>% 
    sqrt()
  
  result_list$step_avg <- c(result_list$step_avg, mean(step_sizes))
  result_list$step_sd <- c(result_list$step_sd, sd(step_sizes))
  
  # only calculate if there are at least 2 movement vectors
  if (nrow(mvt_df) > 1) {
    ## Directional changes (cosine similarity)
    trimmed_mvt1 <- mvt_df[-1,-1] # remove the first row
    trimmed_mvt2 <- mvt_df[-nrow(mvt_df),-1] # remove the last row
    
    dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
    size_product <- step_sizes[-1]*step_sizes[-length(step_sizes)]
    
    cos_sims <- dot_pca/size_product
    
    result_list$dir_avg <- c(result_list$dir_avg, mean(cos_sims))
    result_list$dir_sd <- c(result_list$dir_sd, sd(cos_sims))
  
    # 0 bigsteps will be NA
    ## Burstiness
    burst_df <- data.frame(date_diff = mvt_df$dateStart)
    burst_df$bigstep <- detect_burst(step_sizes, thresh=1)
    step_iei1 <- extract_iei(burst_df)
    
    result_list$step_burst1 <- c(result_list$step_burst1, burstiness(step_iei1))
    
    burst_df$bigstep2 <- detect_burst(step_sizes, thresh=2)
    step_iei2 <- extract_iei(burst_df, burst_ind = 3)
    
    result_list$step_burst2 <- c(result_list$step_burst2, burstiness(step_iei2))
    
    burst_df$fwd <- c(detect_burst(cos_sims, thresh=cos_thresh, scale=FALSE), FALSE)
    dir_iei <- extract_iei(burst_df, burst_ind = 4)
    
    result_list$dir_burst <- c(result_list$dir_burst, burstiness(dir_iei))
  } else {
    result_list$dir_avg <- c(result_list$dir_avg, NA)
    result_list$dir_sd <- c(result_list$dir_sd, NA)
    result_list$step_burst1 <- c(result_list$step_burst1, NA)
    result_list$step_burst2 <- c(result_list$step_burst2, NA)
    result_list$dir_burst <- c(result_list$dir_burst, NA)
  }
  
  wfirst_date <- wfirst_date + wstep_size
  wlast_date <- wlast_date + wstep_size
}

slidw_df <- data.frame(result_list)
slidw_df$start_date <- start_date_seq
slidw_df$end_date <- end_date_seq

slidw_df <- slidw_df[,c(8,9,1:7)]
slidw_df
```

```{r}
write_csv(slidw_df,
          file.path(picasso_path, "results",
                    "slide_window_null6m.csv"))
```


```{r}
nslidw_df <- read_csv(file.path(picasso_path, "results", "slide_window_null6m.csv"))

majorPeriodOnset <- majorPeriodOnset %>% 
  mutate(month = ceiling(12 * ((yearMonthStart+.001) - 
                               floor(yearMonthStart))),
         year = floor(yearMonthStart),
         day = "1", 
         yearMonthDay = paste(year, month, day, sep="-")) %>%
  rowwise() %>%
  mutate(start_date = ymd(yearMonthDay))

majorPeriodOnset <- majorPeriodOnset %>%
  left_join(nslidw_df %>% select(start_date, step_avg, dir_avg, step_burst1, step_burst2, dir_burst))
```

```{r}
nslidw_df %>% 
  ggplot(aes(x = start_date, y = step_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=step_avg+5), alpha=.5) +
  theme_minimal() +
  theme(legend.position = "none")

ggsave(file.path("img", "nslidw_step_size.png"))
  
nslidw_df %>% 
  ggplot(aes(x = start_date, y = step_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=step_avg+5), alpha=.5) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")

nslidw_df %>% 
  ggplot(aes(x = start_date, y = dir_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=dir_avg+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  # coord_cartesian(xlim = c(1898,1928)) +
  theme_minimal() +
  theme(legend.position = "none")

ggsave(file.path("img", "nslidw_dir_change.png"))

nslidw_df %>% 
  ggplot(aes(x = start_date, y = dir_avg)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=dir_avg+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")

nslidw_df %>% 
  ggplot(aes(x = start_date, y = step_burst1)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=step_burst1+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  theme_minimal() +
  theme(legend.position = "none")

ggsave(file.path("img", "nslidw_burstiness.png"))

nslidw_df %>% 
  ggplot(aes(x = start_date, y = step_burst1)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=step_burst1+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")

nslidw_df %>% 
  ggplot(aes(x = start_date, y = dir_burst)) +
  geom_point() +
  geom_vline(xintercept = majorPeriodOnset$start_date, linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=dir_burst+.2), alpha=.5) +
  # scale_x_continuous("year (started)", breaks=seq(1800, 2000, 5)) +
  coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")
```



## Significant movements

```{r}
# calculate individual movements for bootstrapping
shuff_df <- full_df %>% 
  left_join(art_data %>% select(opp, dayStart, dateStart),
            by = "opp") %>% 
  filter(monthStart != 0, dayStart != 0) %>% 
  transform(dateStart = sample(dateStart)) %>% 
  arrange(dateStart) %>% 
  select(dateStart, low_pc1:high_pc100)

shuff_df %>% head()

agg_pca <- shuff_df %>% 
  group_by(dateStart) %>% 
  summarize(across(contains("_pc"), mean))

trimmed_pca1 <- agg_pca[-1,] # remove the first row
trimmed_pca2 <- agg_pca[-nrow(agg_pca),] # remove the last row

mvt_df <- trimmed_pca1 - trimmed_pca2

## Step sizes
nd_step_sizes <- mvt_df %>% 
  mutate(across(contains("_pc"), ~ . ^2)) %>% 
  select(contains("_pc")) %>% 
  rowSums() %>% 
  as.vector() %>% 
  sqrt()

## Directional changes (cosine similarity)
trimmed_mvt1 <- mvt_df[-1,-1] # remove the first row
trimmed_mvt2 <- mvt_df[-nrow(mvt_df),-1] # remove the last row

dot_pca <- rowSums(trimmed_mvt1*trimmed_mvt2)
size_product <- nd_step_sizes[-1]*nd_step_sizes[-length(nd_step_sizes)]

nd_cos_sims <- as.vector(dot_pca/size_product)

# Bootstrapping
resample_nslidw <- bootstraps(nd_step_sizes, times = 10)
bootstp_stsz <- sapply(1:1000, function(i) {
    resample <- sample(nd_step_sizes, size = length(nd_step_sizes), replace = T)
    return(mean(resample))
  }
)

## bootstrap results are very narrow
rect_tib <- tibble(low_conf = quantile(bootstp_stsz, probs = .025),
                   upp_conf = quantile(bootstp_stsz, probs = .975))


# bootstrapped results
ggplot() +
  geom_point(data = nslidw_df, aes(x = start_date, y = step_avg)) +
  geom_hline(yintercept = mean(bootstp_stsz), color = "blue") +
  geom_rect(data=rect_tib, aes(xmin = ymd(18920101), xmax = ymd(19740101),
                               ymin = low_conf, ymax = upp_conf), alpha = .5) +
  theme_minimal() +
  theme(legend.position = "none")


# mean and sd
ggplot() +
  geom_point(data = slidw_df, aes(x = start_date, y = step_avg)) +
  geom_hline(yintercept = mean(bootstp_stsz), color = "blue") +
  geom_rect(aes(xmin = ymd(18920101), xmax = ymd(19740101),
                ymin = mean(nslidw_df$step_avg, na.rm = T) - (2*sd(nslidw_df$step_avg, na.rm = T)),
                ymax = mean(nslidw_df$step_avg, na.rm = T) + (2*sd(nslidw_df$step_avg, na.rm = T))),
            alpha = .5) +
  geom_vline(data=majorPeriodOnset, aes(xintercept = start_date, color=period), linetype='dashed') +
  geom_label(data=majorPeriodOnset, aes(x=start_date, label=period, 
                                        color=period, y=step_avg*10+100), alpha=.5) +
  # coord_cartesian(xlim = c(ymd(18980101),ymd(19280101))) +
  theme_minimal() +
  theme(legend.position = "none")
```



